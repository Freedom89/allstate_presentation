{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src = \"https://kaggle2.blob.core.windows.net/competitions/kaggle/5325/logos/front_page.png\">\n",
    "<br>\n",
    "<h1> Low Yi Xiang </h1> </center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2> Background of me! </h2>\n",
    "\n",
    "- Attendence Guy for DSSG (I hope to retire one day).\n",
    "- Junior Data Scientist in Singapore.\n",
    "- Studied Statistics (my friends would disagree) from NTU. \n",
    "\n",
    "<h2>Prior to Kaggle </h2>\n",
    "\n",
    "- Kaggle is not practical for industry (i still feel it's somewhat true) \n",
    "- Will not use Deep Learning (in most cases)\n",
    "- Will not tune the models to the extreme or stacking for 1% (0.1% gain). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h2> While that is all true... </h2>\n",
    "\n",
    "- Most employers still look for people who exhibit passion in Data Science or Machine Learning. \n",
    "- Happens that Kaggle is one great way to build your portfolio. \n",
    "\n",
    "- People who are in industry (and are much better than i am) still write blogs or present their work in meetups. \n",
    "\n",
    "<h2>Additional insights </h2> \n",
    "\n",
    "- This is my first (serious) Kaggle competition, prior to this i talk to my colleagues or the DSSG organizers about ther competition. **(So i am lucky to have met such people who inspire me in their own way.)**\n",
    "\n",
    "- Thankfully, i managed to achieve top 2%. \n",
    "\n",
    "- It showcases your learning capacity and ability to understand documentation. (I learnt all of these in a month)\n",
    "\n",
    "- Causes you sleepless nights (waiting for your cv score). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2> Logistics ... </h2>\n",
    "\n",
    "<p> - All my code can be found in my github page, [Freedom89](https://github.com/Freedom89) and look for the [Allstate_kaggle repo](https://github.com/Freedom89/Allstate_kaggle).\n",
    "\n",
    "<p> -  The full detailed blog post can be found [here](https://freedom89.github.io/Allstate_kaggle/) or refer to the [index.md](https://github.com/Freedom89/Allstate_kaggle/blob/master/index.md) file on the repo. \n",
    "\n",
    "<p> - Questions are welcomed, but I might take them offline if i think your question requires a heavier discussion. \n",
    "\n",
    "<p> - This may feel like i am spamming you with 'tools', in which case i apologize. \n",
    "\n",
    "<p> - Nevertheless, I hope the content would be useful and we might become kaggle teammates in the future! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<section>\n",
    "    <h1> Contents </h1> \n",
    "    \n",
    "    <p> - Competition \n",
    "    <p> - Features \n",
    "    <p> - Xgboost \n",
    "    <p> - Keras\n",
    "    <p> - Stacking \n",
    "\n",
    "</section>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.stats import skew, boxcox\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time \n",
    "\n",
    "data = pd.read_csv(\"../kaggle_1/data_prep/input/raw/train.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Competition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Competition - background \n",
    "\n",
    "<q>In this recruitment challenge, Kagglers are invited to show off their creativity and flex their technical chops by creating an algorithm which accurately predicts claims severity. Aspiring competitors will demonstrate insight into better ways to predict claims severity for the chance to be part of Allstate’s efforts to ensure a worry-free customer experience.</q>\n",
    "\n",
    "- MAE (mean absolute error) \n",
    "- Anonymized Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Competition - Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9   ...        cont6  \\\n",
       "0   1    A    B    A    B    A    A    A    A    B   ...     0.718367   \n",
       "1   2    A    B    A    A    A    A    A    A    B   ...     0.438917   \n",
       "2   5    A    B    A    A    B    A    A    A    B   ...     0.289648   \n",
       "3  10    B    B    A    B    A    A    A    A    B   ...     0.440945   \n",
       "4  11    A    B    A    B    A    A    A    A    B   ...     0.178193   \n",
       "\n",
       "      cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
       "0  0.335060  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493   \n",
       "1  0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
       "2  0.315545  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709   \n",
       "3  0.391128  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077   \n",
       "4  0.247408  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011   \n",
       "\n",
       "     cont14     loss  \n",
       "0  0.714843  2213.18  \n",
       "1  0.304496  1283.60  \n",
       "2  0.774425  3005.09  \n",
       "3  0.602642   939.85  \n",
       "4  0.432606  2763.85  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Features - Xgb Interactions\n",
    "\n",
    "- Use [Xgbfi](https://github.com/Far0n/xgbfi) by far0n to find N-way interactions for categorical features \n",
    "\n",
    "|col1|col2|new_feat = col1 + col2|\n",
    "|---|---|---|\n",
    "|A|B|AB|\n",
    "|C|D|CD|\n",
    "\n",
    "- Use this tool to find feature interactions for Regression. \n",
    "\n",
    "## Tuning Xgb \n",
    "\n",
    "- As an alternative to grid search, i have explored using [hyperopt](https://github.com/hyperopt/hyperopt).\n",
    "- [Example of how i used hyperopt for my xgb.](https://github.com/Freedom89/Allstate_kaggle/blob/master/hyperopt_results/hyper_opt_xgb.ipynb)\n",
    "- [Results of hyperopt](https://github.com/Freedom89/Allstate_kaggle/blob/master/hyperopt_results/hyper_opt_power2.csv)\n",
    "    - Start with a relatively higher ETA for hyperopt, find out the 'best' params and lower the ETA for actual training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Features - Feature Engineering ( boxcox )\n",
    "\n",
    "Other than log the target as well as standardization of input features,\n",
    "\n",
    "Boxcox which aims to provide an automatic way of transforming your (cont) features to make it more even (normal). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "feat_name = 'cont6'\n",
    "ss = StandardScaler()\n",
    "\n",
    "#temp0 = ss.fit_transform(data[feat_name].values.reshape(-1,1))\n",
    "temp0 = data[feat_name]\n",
    "\n",
    "temp = data[feat_name] + 1 #prevent the log of 0 \n",
    "temp, lam = boxcox(temp)\n",
    "#temp = ss.fit_transform(temp.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHNFJREFUeJzt3X+QHOV95/H3R4BEgYEC2+yWJbQiBoHwjwhxEU6Rqghz\nxy+nDEUFLJMy2ECOsuAgR10FiZxPyIWL4DooDJw4E2SDFGyVTCqADywkB28cXAjkBCxg+SFiSyCB\nFpAQNnZMCfS9P/pZdnY1vTOa6Znpnf28qqY0+0x3z7dbu/Od7qef56uIwMzMrJpJnQ7AzMzKy0nC\nzMxyOUmYmVkuJwkzM8vlJGFmZrmcJMzMLJeThE1okn4l6bMNrDdT0pOS3pZ0eStiMyuDfTsdgNk4\n9dfAIxFxfKcDMWsln0mYNaYPeLaRFSXtU3AsZi3jJGEGcyU9K2m7pGWSJgNI+rN0SektSY9K+mRq\n/yfgZOD/SPq1pKMkHSxpuaTX0yWsvxnauKQL0/o3SXoTWJzaL5I0kN73R5Kmd2DfzcbkJGEG5wP/\nBfg4cAzwPyXNBpYBfwkcBnwb+KGk/SLiFOBfgMsi4uCIeAm4DTgImAHMAy6Q9JWK9zgReAk4HPiG\npLOAhcDZwEfT9r7f4v0022tOEmZwa0S8GhE7gW+QJY3/CvzfiPh5ZFYA7wKfGb2ypEnAF4CFEfG7\niNgM3Ah8qWKxrRGxNCJ2R8S7wKXA9RHxYkTsBv4WmC3piJbuqdlecpIwgy0VzzcDHwOmA/9D0o70\neAuYll4b7SNkN4G8PGo7Uyt+fmXUOn3At4a2D2wHYtQ6Zh3nu5vMoPLb+3RgK9mH+nURcX0d678J\n7CL74H8+tfWl7QwZPd3yy2n7vsRkpeYzCTO4TNJUSYcBfwOsBO4EvippLoCkAyWdKenA0Suny0Wr\nyPoaPiSpD/jvwIox3vPbwDWSjkvbP0TSnxe7W2bNc5KwiS6A7wFryDqWNwLfiIh/BS4BbkuXg14E\nLhy1XqUrgN8BvwR+Cvx9RHw3900j7iPrh1gpaSewATi9kD0yK5BqFR2SNA1YDvQAu4E7IuJWSYvJ\n7vx4PS16TUSsTussAi4C3gOujIg1qX0OcBewP/BQRPxVap+c3uMEslP3L0RE5fVdMzPrgHrOJN4D\nroqITwB/DFwu6dj02k0RMSc9hhLELOA8YBZwBrBUktLytwMXR8RMYKak01L7xcCOiDgauBn4ZhE7\nZ2ZmzamZJCJiW0Q8lZ6/AzzH8B0YqrLKWcDKiHgvIjaRnb7PldQLHBQR69Nyy8nuER9a5+70/F7g\nlAb2xczMCrZXfRKSZgCzgcdT0+WSnpJ0p6RDUttURt7utzW1TWXkrYZbGE42H6wTEe8DO1MnopmZ\ndVDdSULSh8i+5V+ZziiWAn8QEbOBbWSDh4pS7QzFzMzarK5xEpL2JUsQKyLifoCIeKNikb8Dfpie\nb2XkfefTUltee+U6r6bJzw6OiB1V4hi7l93MzKqKiIa+fNd7JvEdYCAivjXUkPoYhpwDPJOePwDM\nlzRZ0pHAUcATEbENeFvS3NSRfQFwf8U6Q7cXngs8khdIRPgRweLFizseQ1kePhY+Fj4WYz+aUfNM\nQtJJwF8AT0t6kuz+8GuA89MkaLuBTWRz0RARA5JWAQNko1AXxHCUlzHyFtjVqX0ZsELSRrLpCeY3\ntVdmZlaImkkiIn4GVJv/fnWVtqF1rgf2mM4gsgFKn6rS/i7ZbbNmZlYiHnE9Ts2bN6/TIZSGj8Uw\nH4thPhbFqDniukwkxXiK18ysDCQRLe64NjOzCchJwszMcjlJWGn09s5AUsOP3t4Znd4Fs67jPgkr\njWz4TDP/v2r6nnCzbuQ+CTMzawknCTMzy+UkYWZmuZwkzMwsl5OEmZnlqpkkJE2T9IikZyU9LemK\n1H6opDWSXpD0cEXRISQtkrRR0nOSTq1onyNpg6QXJd1c0T5Z0sq0zmOSphe9o2ZmtvcaqXF9Wapx\nvRD4cUQcQza19yIAScfhGtdmZl2h0RrX0xhZl/puhutVfx7XuJ5wmh0IN/w9wszKpNEa1+uAnogY\nhCyRAIenxVzjegIaHNxMNhCumYeZlU0zNa5H/1UX+Vfur5VmZiXQcI1rYFBST0QMpktJr6f2ltW4\nBrj22ms/eD5v3jzPGW9mNkp/fz/9/f2FbKuuuZskLQfejIirKtpuIOtsvkHS1cChEbEwdVzfA5xI\ndhlpLXB0RISkdcAVwHrgQeCWiFgtaQHwyYhYIGk+cHZE7FHC1HM3lVfz8y5BdgLpuZvMitbM3E01\nk0Sqcf1T4GmGLx5fAzwBrCI7A9gMnBcRO9M6i8juWNpFdnlqTWo/gZE1rq9M7VOAFcDxpBrXqdN7\ndCxOEiXlJGFWXi1NEmXiJFFeThJm5eVZYM3MrCWcJKyLTGl6rIYLF5mN5MtNVoiyXG4qIgb/jlm3\n8eUmMzNrCScJMzPL5SRhZma5nCTMzCyXk4SZmeVykjAzs1xOEmZmlstJwszMcjlJmJlZrppJQtIy\nSYOSNlS0LZa0RdK/pcfpFa8tkrRR0nOSTq1onyNpg6QXJd1c0T5Z0sq0zmOSphe5g2Zm1rh6ziS+\nC5xWpf2miJiTHqsBJM0CzgNmAWcASzVcvPh24OKImAnMlDS0zYvJ6lIcDdwMfLPx3TEzsyLVTBIR\n8SjwVpWXqs0DchawMiLeS/UgNgJzU+W6gyJifVpuOXB2xTp3p+f3AqfUH76ZmbVSM30Sl0t6StKd\nkg5JbVOBVyqW2ZrapgJbKtq3pLYR60TE+8BOSYc1EdeE09s7w7OfmllL1FXjuoqlwNdTSdLrgBuB\nSwqKacyZCl3jek+Dg5tpdvbTwcGGJog0sxLqRI3rPuCHEfHpsV6TtBCIiLghvbYaWExW3vQnETEr\ntc8H/jQivjq0TEQ8Lmkf4LWIODwnDk8VXkVR03Q3c2w9VbhZebVjqnBR8Q0/9TEMOQd4Jj1/AJif\n7lg6EjgKeCIitgFvS5qbOrIvAO6vWOfC9Pxc4JFGdsTMzIpX83KTpO8B84APS3qZ7MzgZEmzgd3A\nJuBSgIgYkLQKGAB2AQsqvvpfBtwF7A88NHRHFLAMWCFpI7AdmF/InpmZWdNcma4L+HJTUetn2/Dv\nmHUbV6YzM7OWcJIwM7NcThJmZpbLScLMzHI5SZiZWS4nCTMzy+UkYWZmuZwkzGwPzU4a6Qkju4cH\n03UBD6Yran3IJgR4t+G1J006gN27f9dUBD09fWzbtqmpbTSr+f9PD0osk2YG0zlJdAEniaLWL08M\nnf49d5LoLh5xbWZmLdFojetDJa2R9IKkhyuKDrnGtZlZF2m0xvVC4McRcQzZ1N6LACQdh2tcj1NT\nmuqoNLPu1GiN68q61HczXK/687jG9Tj1Ltk16EYfZtaNGu2TODwiBgFSQaGhSnKucW1m1kUarXE9\nWpFfJV3j2sysCUXWuG40SQxK6omIwXQp6fXUvhU4omK5aaktr71ynVdTjeuDI2JH3htXJgmz7jSl\nqX6eMoyzsM4a/QV6yZIlDW+roRrXZHWpv5yeX8jIetWucW3WlOb6hwYHN3cgZutWjda4/lvgB5Iu\nAjaT3dHkGtdmljR3NgQ+IyoLj7juAh7t7BhGr9/s30kRI667YeR5t2hmxHVRHddmVhrNf4s3G+Jp\nOUqg2Rk3zUZqdsyLv73bMF9uKoGynNo7BsdQthi68e+9EzzBn5mZtYSThJmZ5XKSMDOzXE4SZmZV\nNHtDSbeUcXXHdQm449oxOIbq2+jk33sZKj4WxR3XZmaj+NbyYvhMogR8JuEYHEP1bXS27nrn96Eo\nPpMwM7OWaCpJSNok6ReSnpT0RGorrP61mZl1VrNnEruBeRFxfETMTW1F1r82swnLddfLoNkkoSrb\nKLL+tZlNWK67XgbNJokA1kpaL+mS1NZTYP1rMzProGanCj8pIl6T9FFgjaQX2DOFO6WbmY1TTSWJ\niHgt/fuGpPuAuRRb/3oPlTWuR9dxNTMz6O/vp7+/v5BtNTxOQtIBwKSIeEfSgcAaYAlwCrAjIm6Q\ndDVwaEQsTB3X9wAnkl1OWgscHREhaR1wBbAeeBC4paK8aeV7epxE9S00uX4R23AMjqHbYvA4CWju\nTKIH+EdJkbZzT0SskfRzYFVB9a/NzKyDPOK6BHwm4RgcQxljKGIf9ie7S6sxPT19bNu2qckYmjuT\ncJIoAScJx+AYyhhDOfahiM88T8thZmYt4SRhZma5nCTMzCyXk4SZmeVykjAzs1xOEmZmlstJwszM\ncjlJmJlZLicJMzPL1exU4WZm1jJTmq6y19PT19T6npajBDwth2NwDGWMoRv2YWgbjP9pOSSdLul5\nSS+mKcZtTP2dDqBE+jsdQIn0dzoA6zKlSBKSJgG3AacBnwC+KOnYzkZVn97eGU0Va2/8VLK/yN0Y\n5/o7HUCJ9Hc6AOsyZemTmAtsjIjNAJJWAmcBz4+10tq1a/nNb37T8Jvut99+fO5zn2PSpMZz5eDg\nZoo6HTQzK5uyJImpwCsVP28hSxy5BgYGOPXUU5t+44ceeogzzjij6e2YmXWjsiSJujXb0z/amWee\nWcBWioipkW0sKUEMRa7fzDaGjsVEPw6OoVzrlyWGxpUlSWwFplf8PC21jdBo77yZmTWmFB3XwHrg\nKEl9kiYD84EHOhyTmdmEV4oziYh4X9LlwBqyxLUsIp7rcFhmZhPeuBpMZ2Zm7VWWy01mZlZCThJm\ne0nSdZLekPRqp2MxazVfbjLbC5KOAF4AjoiI7ZL6gF8B+0bE7s5GZ1Y8n0mY7Z0+4M2I2J5+HpqB\nraHbsyXtU1RgZq3gJGFWhaSrJb0k6deSnpF0tqRTyO7A+1hq/w7wz2mVnantxLT+RZIGJG2X9CNJ\n0yu2vVvSAkkvAi+2fefM9kIpboE1K6GXgJMiYlDSucDfAx8HzgBWRMR0gHS56ZfAwUPz2Es6C1gI\n/FnazkLg+8BJFds/C/gj4Pft2R2zxrhPwqwOkp4E/hfwa6onif2G+iQkPQT8ICK+m36eBPwGODYi\nXpG0Gzg5Iv65yluZlYovN5lVIekCSU9KekvSW2RT2H+kztX7gG9J2iFpB7CdrN9iasUyW4qN2Kw1\nfLnJbJTUf3AH2bf9x1Lbk1TvnK52Kv4ycF1EfH+Mt/EpvI0LPpMw29OBwG7gTUmTJH0F+GTOsm+k\nZT9e0fZt4BpJxwFIOkTSn7cyYLNW8ZmE2SgR8ZykG4F1wPvAcuDRnGX/Q9I3gJ9J2hc4PSLuk3Qg\nsDKdlbwNrAXuHVqt5TthVpCaHdeSppH9kfSQfWO6IyJulbQY+Evg9bToNRGxOq2zCLgIeA+4MiLW\npPY5wF3A/sBDEfFXqX1yeo8TgDeBL0TEywXup5mZNaCey03vAVdFxCeAPwYur6g/fVNEzEmPoQQx\nCzgPmEV2u+BSDVcKuh24OCJmAjMlnZbaLwZ2RMTRwM3AN4vYOTMza07NJBER2yLiqfT8HeA5hu/S\nqNaRdxawMiLei4hNwEZgrqRe4KCIWJ+WWw6cXbHO3en5vcApDeyLmZkVbK86riXNAGYDj6emyyU9\nJelOSYekttH1qremtqmMvO1vC8PJ5oN1IuJ9stGrh+1NbGZmVry6O64lfYjsW/6VEfGOpKXA1yMi\nJF0H3AhcUlBcVefBkeQOPzOzBjRa/rmuM4l018a9ZCNN709v+EYM93r/HTA3Pd8KHFGx+lC96rz2\nEeukCc8Ojogd1WKJCD8iWLx4ccdjKMvDx8LHwsdi7Ecz6r3c9B1gICK+NdSQ+hiGnAM8k54/AMyX\nNFnSkcBRwBMRsQ14W9Lc1JF9AXB/xToXpufnAo80tDdmZlaompebJJ0E/AXwdBp1GsA1wPmSZpPd\nFrsJuBQgIgYkrQIGgF3AghhOZZcx8hbY1al9GbBC0kayKQzmF7J3ZmbWlJpJIiJ+BlSb8351lbah\nda4Hrq/S/q/Ap6q0v0t226zVad68eZ0OoTR8LIb5WAzzsSjGuJoFVlKMp3jNzMpAEtHKjmszM5uY\nnCTMzCyXk4QB0Ns7A0m5j97eGZ0O0cw6wH0SBmTXLMeenFRN329tZp3hPgkzM2sJJwkzM8vlJGFm\nZrmcJMzMLJeThJmZ5XKSMDOzXDWThKRpkh6R9KykpyVdkdoPlbRG0guSHq4oOoSkRZI2SnpO0qkV\n7XMkbZD0oqSbK9onS1qZ1nksFY83M7MOa6TG9WWpxvVC4McRcQzZ1N6LACQdh2tcm5l1hUZrXE9j\nZF3quxmuV/15XOPazKwrNFrjeh3QExGDkCUS4PC0mGtcm5l1ibqTxOga1+w5h0ORczY0NHzczMyK\nVbPoEFSvcQ0MSuqJiMF0Ken11N5MjetXa9W4vvbaaz94Pm/ePBcWaZspDHct7amnp49t2za1Lxwz\ny9Xf309/f38h26prgj9Jy4E3I+KqirYbyDqbb5B0NXBoRCxMHdf3ACeSXUZaCxwdESFpHXAFsB54\nELglIlZLWgB8MiIWSJoPnB0Re5Qw9QR/rVPPBH+eANBsfGpmgr+aSSLVuP4p8DTZp8RQjesngFVk\nZwCbgfMiYmdaZxHZHUu7yC5PrUntJzCyxvWVqX0KsAI4nlTjOnV6j47FSaJFnCTMuldLk0SZOEm0\njpOEWffyVOFmZtYSThJmZpbLScLMzHI5SZiZWS4nCTMzy+UkYWZmuZwkzMwsl5OEmZnlcpKYIHp7\nZyAp92FmVo1HXE8QRYyo9ohrs/HJI67NzKwlnCTMzCxXzSQhaZmkQUkbKtoWS9oi6d/S4/SK1xZJ\n2ijpOUmnVrTPkbRB0ouSbq5onyxpZVrnMUnTi9xBMzNrXD1nEt8FTqvSflNEzEmP1QCSZgHnAbOA\nM4ClGu4VvR24OCJmAjMlDW3zYrK6FEcDNwPfbHx3zMysSDWTREQ8CrxV5aVqnSBnASsj4r1UD2Ij\nMDdVrjsoItan5ZYDZ1esc3d6fi9wSv3hm5lZKzXTJ3G5pKck3SnpkNQ2FXilYpmtqW0qsKWifUtq\nG7FORLwP7JR0WBNxmZlZQeqqcV3FUuDrqSTpdcCNwCUFxTTmbVqucW1mNrZO1LjuA34YEZ8e6zVJ\nC4GIiBvSa6uBxWTlTX8SEbNS+3zgTyPiq0PLRMTjkvYBXouIw3Pi8DiJBk2EcRK9vTMYHNw85jI9\nPX1s27apPQGZlUQ7xkmIim/4qY9hyDnAM+n5A8D8dMfSkcBRwBMRsQ14W9Lc1JF9AXB/xToXpufn\nAo80siNmWYKIMR+1koiZjVTzcpOk7wHzgA9LepnszOBkSbOB3cAm4FKAiBiQtAoYAHYBCyq++l8G\n3AXsDzw0dEcUsAxYIWkjsB2YX8iemZlZ0zwtxwQxES431d5HKEOcZu3maTlsXKg1yWBv74xOh2hm\no/hMYoIow5lEPTGMtY16OqZ9JmG2p2bOJJwkJohuSBLN70Pt9zDrRs0kiUbHSZiNMsV1Kcy6kJOE\nFeRd6vkWb2bjizuuzcwsl5OEmZnl8uUmKxH3a5iVjZOElUitfg0nELN28+Umswoe8Gc2ksdJTBDt\nGCdR391NnY+h2bEY/h208aal03Lk1Lg+VNIaSS9Ierii6JBrXJuZdZFGa1wvBH4cEceQTe29CEDS\ncbjGtZlZ12i0xnVlXeq7Ga5X/Xlc49rMrGs02nF9eEQMAqSCQkOV5Fzj2kpuypgd02Y2UlG3wBbZ\nk+ca19ZCvs3Wul+RNa4bTRKDknoiYjBdSno9tW8FjqhYblpqy2uvXOfVVOP64IjYkffGlUlioqg1\nRbbrNptZpdFfoJcsWdLwthqqcU1Wl/rL6fmFjKxX7RrXe6nWvfm1ajcPDm4bc31fRjGzRtUcJ1FZ\n4xoYJKtxfR/wA7IzgM3AeRGxMy2/iOyOpV3AlRGxJrWfwMga11em9inACuB4Uo3r1OldLZauHCfR\n+jEMRWzDMQy93o2/g9bdXHRonHOSGF8xdOPvoHU317g2M7OWcJIwM7NcThJmZpbLScLMzHI5SZiZ\nWS4nCTMzy+UkYWZmuZwkzMwsl5OEmZnlcpIwM7NcThJmZparqSQhaZOkX0h6UtITqa2w+tdmZtZZ\nzZ5J7AbmRcTxETE3tRVZ/9rMzDqo2SShKtsosv61mZl1ULNJIoC1ktZLuiS19RRY/9rMzDqo2RrX\nJ0XEa5I+CqyR9AJ7TsY/4Sffr1V+1MysrJpKEhHxWvr3DUn3AXMptv71HiprXI+u41pWw+VH87i8\n6PgxZcxysK43bmXQ399Pf39/IdtquDKdpAOASRHxjqQDgTXAEuAUYEdE3CDpauDQiFiYOq7vAU4k\nu5y0Fjg6IkLSOuAKYD3wIHBLRKyu8p7jsjJd6yvPTZyqcOMhhvH4O2rdrZnKdM2cSfQA/ygp0nbu\niYg1kn4OrJJ0Ean+NUBEDEhaBQyQ1b9eUPGJfxkj61/vkSDMzKz9XOO6DXwmMbFiGI+/o9bdXOPa\nzMxawknCzMxyOUmYmVkuJwkzM8vlJGFmZrmcJMzMLJeThJmZ5XKSMDOzXE4SZmaWy0nCzMxyOUmY\nmVmu0iQJSadLej7Vub660/GYmVlJkoSkScBtwGnAJ4AvSjq2s1GVXX+nAyiR/k4HUBpF1RDoBj4W\nxShFkiArVrQxIjZHxC5gJVmtbMvV3+kASqS/0wGUhj8Yh/lYFKPZ8qVFGV3/egtZ4sj1zjvvcM01\nS/jtb/8jd5m+vml87WtXj1lJzMzM8pUlSey1gYEBbr31f4+5jDSJhQuvYvLkyQ2/T6361JMmHcDu\n3b9rePtmZmVWiqJDkj4DXBsRp6efFwIRETeMWq7zwZqZjUONFh0qS5LYB3iBrD72a8ATwBcj4rmO\nBmZmNsGV4nJTRLwv6XJgDVln+jInCDOzzivFmYSZmZVTWW6BHaGegXWSbpG0UdJTkma3O8Z2qXUs\nJJ0v6Rfp8aikT3Uiznaod8ClpD+StEvSOe2Mr53q/BuZJ+lJSc9I+km7Y2yXOv5GDpb0QPqseFrS\nlzsQZstJWiZpUNKGMZbZ+8/NiCjVgyxxvQT0AfsBTwHHjlrmDODB9PxEYF2n4+7gsfgMcEh6fvpE\nPhYVy/0T8P+Aczoddwd/Lw4BngWmpp8/0um4O3gsFgHXDx0HYDuwb6djb8Gx+BNgNrAh5/WGPjfL\neCZRz8C6s4DlABHxOHCIpJ72htkWNY9FRKyLiLfTj+vIxpx0o3oHXP434F7g9XYG12b1HIvzgX+I\niK0AEfFmm2Nsl3qORQAHpecHAdsj4r02xtgWEfEo8NYYizT0uVnGJFFtYN3oD77Ry2ytskw3qOdY\nVLoE+FFLI+qcmsdC0seAsyPidqCbR1DW83sxEzhM0k8krZf0pbZF1171HIvbgOMkvQr8AriyTbGV\nTUOfm6W4u8maJ+lk4Ctkp5wT1c1A5TXpbk4UtewLzAE+CxwIPCbpsYh4qbNhdcRpwJMR8VlJHwfW\nSvp0RLzT6cDGgzImia3A9Iqfp6W20cscUWOZblDPsUDSp4E7gNMjYqzTzfGsnmPxn4CVyuZh+Qhw\nhqRdEfFAm2Jsl3qOxRbgzYj4PfB7ST8F/pDs+n03qedYfAW4HiAi/l3Sr4BjgZ+3JcLyaOhzs4yX\nm9YDR0nqkzQZmA+M/iN/ALgAPhitvTMiBtsbZlvUPBaSpgP/AHwpIv69AzG2S81jERF/kB5HkvVL\nLOjCBAH1/Y3cD/yJpH0kHUDWUdmNY4/qORabgf8MkK7BzwR+2dYo20fkn0E39LlZujOJyBlYJ+nS\n7OW4IyIeknSmpJeA35J9U+g69RwL4GvAYcDS9A16V0SMOTnieFTnsRixStuDbJM6/0ael/QwsAF4\nH7gjIgY6GHZL1Pl7cR1wV8WtoX8dETs6FHLLSPoeMA/4sKSXgcXAZJr83PRgOjMzy1XGy01mZlYS\nThJmZpbLScLMzHI5SZiZWS4nCTMzy+UkYWZmuZwkzMwsl5OEmZnl+v8Kn8cCxRqCagAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1101ae290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(2, sharex=True)\n",
    "axarr[0].hist(temp0,20);\n",
    "axarr[0].set_title('before');\n",
    "axarr[1].hist(temp,20);\n",
    "axarr[1].set_title('after');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Features - Encoding of Categorical features \n",
    "\n",
    "Most common (two) types of encoding (i know),\n",
    "\n",
    "* Label Encoding\n",
    "\n",
    "|col|trans|\n",
    "|---|---|\n",
    "|A|1|\n",
    "|B|2|\n",
    "|C|3|\n",
    "\n",
    "* one - hot encoding\n",
    "\n",
    "|col|is_A|is_B|is_C|\n",
    "|---|---|---|---|---|\n",
    "|A|1|0|0|\n",
    "|B|0|1|0|\n",
    "|C|0|0|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Features - Lexical Encoding\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "26\n",
      "27\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "def encode(charcode):\n",
    "    r = 0\n",
    "    ln = len(str(charcode))\n",
    "    for i in range(ln):\n",
    "        r += (ord(str(charcode)[i]) - ord('A') + 1) * 26 ** (ln - i - 1)\n",
    "    return r\n",
    "\n",
    "print encode('A')\n",
    "print encode('B')\n",
    "print encode('Z')\n",
    "print encode('AA')\n",
    "print encode('AB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - Understanding Learning Task Parameters \n",
    "\n",
    "If you refer to the xgboost parameters documentation [here](https://github.com/dmlc/xgboost/blob/master/doc/parameter.md),\n",
    "\n",
    "Specify the learning task and the corresponding learning objective. The objective options are below:\n",
    "* objective [ default=reg:linear ]\n",
    " - **\"reg:linear\" --linear regression**\n",
    " - \"reg:logistic\" --logistic regression\n",
    " - \"binary:logistic\" --logistic regression for binary classification, output probability\n",
    " - \"binary:logitraw\" --logistic regression for binary classification, output score before logistic transformation\n",
    " - \"count:poisson\" --poisson regression for count data, output mean of poisson distribution\n",
    "   - max_delta_step is set to 0.7 by default in poisson regression (used to safeguard optimization)\n",
    " - \"multi:softmax\" --set XGBoost to do multiclass classification using the softmax objective, you also need to set num_class(number of classes)\n",
    "\n",
    " - ... \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - Understanding Eval\n",
    "\n",
    "* eval_metric [ default according to objective ]\n",
    "    - \"rmse\": [root mean square error](http://en.wikipedia.org/wiki/Root_mean_square_error)\n",
    "    - **\"mae\"**: [mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error)\n",
    "    - \"logloss\": negative [log-likelihood](http://en.wikipedia.org/wiki/Log-likelihood)\n",
    "    - \"error\": Binary classification error rate. It is calculated as #(wrong cases)/#(all cases). For the predictions, the evaluation will regard the instances with prediction value larger than 0.5 as positive instances, and the others as negative instances.\n",
    "    - ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - Problem! \n",
    "The learning objective as 'Linear' while the evaluation metric is 'mae', what can we do?\n",
    "### Additional Math:\n",
    "It turns out that when you are optimizing for Mean Squared Error, finding the **Mean** optimizes the error.\n",
    "If you are optimizing for mean absolute error, finding the **Median** optimizes the error. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  1000.3960478\n",
      "The median is:  694.0\n",
      "The error by using mean is:  735.784095754\n",
      "The error by using median is:  693.1531646\n",
      "increasing 1 point from median:  693.1539714\n",
      "decreasing 1 point from median:  693.1533366\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337);size = 5000000\n",
    "vector = np.random.exponential(size=size);vector = np.ceil(vector*1000)\n",
    "def mean_mae(x_hat,size = size):return np.sum(np.absolute(vector-x_hat))/size\n",
    "print 'The mean is: ' , np.mean(vector)\n",
    "print 'The median is: ' , np.median(vector)\n",
    "print 'The error by using mean is: ' , mean_mae(np.mean(vector))\n",
    "print 'The error by using median is: ' ,mean_mae(np.median(vector))\n",
    "print 'increasing 1 point from median: ' ,mean_mae(np.median(vector)+1)\n",
    "print 'decreasing 1 point from median: ' ,mean_mae(np.median(vector)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - Gradient Descent  of L1 and L2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class L1(object):\n",
    "    def __init__(self,vector,size,guess):  \n",
    "        self.vector = vector\n",
    "        self.guess = guess\n",
    "        self.size = size\n",
    "    def jacob(self):\n",
    "        return np.sum(np.sign((self.vector-self.guess)))/self.size\n",
    "    \n",
    "class L2(object):\n",
    "    def __init__(self,vector,size,guess):  \n",
    "        self.vector = vector\n",
    "        self.guess = guess\n",
    "        self.size = size\n",
    "    def jacob(self):\n",
    "        return np.sum(self.vector-self.guess)/self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - L1 gradient descent\n",
    "Note that it takes close to 50 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient is : -0.030957  with value: 725\n",
      "The gradient is : -0.02076  with value: 714.724892\n",
      "The gradient is : -0.0137276  with value: 707.806204\n",
      "The gradient is : -0.0097468  with value: 703.1710776\n",
      "The gradient is : -0.0067868  with value: 700.0471752\n",
      "The gradient is : -0.0038096  with value: 697.945108\n",
      "The gradient is : -0.0028124  with value: 696.5688536\n",
      "The gradient is : -0.001808  with value: 695.640756\n",
      "The gradient is : -0.0008068  with value: 694.9616088\n",
      "The gradient is : -0.0008068  with value: 694.6388888\n",
      "The output is:  694.3161688\n",
      "The time taken is, :  49.7573640347\n"
     ]
    }
   ],
   "source": [
    "initial_guess = 725\n",
    "learning_rate = 4\n",
    "L1_descent = L1(vector,size,initial_guess)\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print 'The gradient is :', L1_descent.jacob(), ' with value:' , initial_guess\n",
    "    next_guess = initial_guess + learning_rate*L1_descent.jacob()\n",
    "    initial_guess = next_guess\n",
    "    L1_descent = L1(vector,size,next_guess)\n",
    "print 'The output is: ', next_guess\n",
    "print 'The time taken is, : ', time.time() - start \n",
    "#the mean is:  1000.3960478 the median is:  694.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - L2 gradient descent\n",
    "Much faster! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient is : 275.3960478  with value: 725\n",
      "The gradient is : 1.41932932335  with value: 998.976718477\n",
      "The gradient is : 0.00731490427759  with value: 1000.3887329\n",
      "The output is:  1000.3960101\n",
      "The time taken is, :  2.02755618095\n"
     ]
    }
   ],
   "source": [
    "initial_guess = 725\n",
    "learning_rate = 0.1\n",
    "L2_descent = L2(vector,size,initial_guess)\n",
    "start = time.time()\n",
    "for i in range(150):\n",
    "    if i % 50 ==  0:\n",
    "        print 'The gradient is :', L2_descent.jacob(), ' with value:' , initial_guess\n",
    "        \n",
    "    next_guess = initial_guess + learning_rate*L2_descent.jacob()\n",
    "    initial_guess = next_guess\n",
    "    L2_descent = L2(vector,size,next_guess)\n",
    "print 'The output is: ', next_guess\n",
    "print 'The time taken is, : ', time.time() - start \n",
    "#the mean is:  1000.3960478 the median is:  694.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - L2 gradient descent with log-transformed features \n",
    "\n",
    "Recall that L2 penalizes more for points far away from the mean, while mae penalizes equally throughout.\n",
    "\n",
    "In that case, we can transform the features with log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  1000.3960478\n",
      "The median is:  694.0\n",
      "The log mean is 6.33421520082 the exp of the log mean is: 563.526973894\n",
      "The error by using mean is:  735.784095754\n",
      "The error by using median is:  693.1531646\n",
      "The error by using log-mean is:  702.006505008\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337);size = 5000000\n",
    "vector = np.random.exponential(size=size);vector = np.ceil(vector*1000)\n",
    "print 'The mean is: ' , np.mean(vector)\n",
    "print 'The median is: ' , np.median(vector)\n",
    "print 'The log mean is', np.mean(np.log(vector)), 'the exp of the log mean is:' , np.exp(np.mean(np.log(vector))) \n",
    "print 'The error by using mean is: ' , mean_mae(np.mean(vector))\n",
    "print 'The error by using median is: ' ,mean_mae(np.median(vector))\n",
    "vector_log = np.log(vector);mean_vector_log = np.exp(np.mean(vector_log))\n",
    "print 'The error by using log-mean is: ' ,mean_mae(mean_vector_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - L2 gradient descent with log-transformed features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient is : -3.66578479918  with value: 10\n",
      "The gradient is : -0.0188926308134  with value: 6.35310783164\n",
      "The gradient is : -9.73683722883e-05  with value: 6.3343125692\n",
      "The output is:  6.33421570264\n",
      "The time taken is, :  8.58931088448\n"
     ]
    }
   ],
   "source": [
    "initial_guess = 10\n",
    "learning_rate = 0.1\n",
    "L2_descent = L2(np.log(vector),size,initial_guess)\n",
    "start = time.time()\n",
    "for i in range(150):\n",
    "    if i % 50 ==  0:\n",
    "        print 'The gradient is :', L2_descent.jacob(), ' with value:' , initial_guess\n",
    "        \n",
    "    next_guess = initial_guess + learning_rate*L2_descent.jacob()\n",
    "    initial_guess = next_guess\n",
    "    L2_descent = L2(np.log(vector),size,next_guess)\n",
    "    \n",
    "print 'The output is: ', next_guess\n",
    "print 'The time taken is, : ', time.time() - start \n",
    "#the mean is:  1000.3960478 the median is:  694.0 the log mean is 6.33421520082"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - Another example\n",
    "\n",
    "Notice that calculating the median is almost 20 times slower!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean is:  1000.3960478\n",
      "0.00365710258484\n",
      "the median is:  694.0\n",
      "0.0586512088776\n"
     ]
    }
   ],
   "source": [
    "clock1 = time.time()\n",
    "print 'the mean is: ', np.mean(vector)\n",
    "print time.time() - clock1\n",
    "\n",
    "clock2 = time.time()\n",
    "print 'the median is: ', np.median(vector)\n",
    "print time.time() - clock2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - Conclusion\n",
    "\n",
    "Optimizing by MAE is still the best option! But there is no obejctive for MAE, what do we do?\n",
    "\n",
    "For those who are familar, you may know that $y = |x|$ is not differentiable at $x=0$. \n",
    "\n",
    "As seen from the following graph, when performing gradient descent is going to be very tricky.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEKCAYAAAD0Luk/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110407150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-1,1,0.001)\n",
    "f, (ax1, ax2,ax3) = plt.subplots(3, 1, sharex=True)\n",
    "ax1.plot(x,np.abs(x)); ax1.set_title('function')\n",
    "ax2.plot(x,np.sign(x),color = 'r'); ax2.set_title('Jacob')\n",
    "ax3.plot(x,1/np.abs(x),color = 'g'); ax3.set_title('Hessian');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - Numercial approximation \n",
    "\n",
    "I will skip the details but it turns out that there is a very nice function called the `fair` function that 'smooths' the gradient of the MAE function. \n",
    "\n",
    "Function = $c^2 [\\frac{|x|}{c} - log(1+\\frac{|x|}{c}]$, Jacob = $\\frac{x}{1+\\frac{|x|}{c}}$, Hess = $\\frac{1}{1+\\frac{|x|}{c}}$ \n",
    "\n",
    "\n",
    "If you are still interested, click [here](http://research.microsoft.com/en-us/um/people/zhang/INRIA/Publis/Tutorial-Estim/node24.html).\n",
    "\n",
    "Lets define the code for the fair function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class fair_obj(object):\n",
    "    def __init__(self,vector,c=2):\n",
    "        self.vector = vector\n",
    "        self.c = c\n",
    "    def func(self):\n",
    "        c = self.c\n",
    "        abs_x_c = np.abs(self.vector) / c\n",
    "        return((c**2)*(abs_x_c - np.log(1+abs_x_c)))\n",
    "    def jacob(self):\n",
    "        c = self.c\n",
    "        abs_x_c = np.abs(self.vector) / c\n",
    "        return(x / (1+abs_x_c))\n",
    "    def hess(self):\n",
    "        c = self.c\n",
    "        abs_x_c = np.abs(self.vector) / c\n",
    "        return(1 / (1+abs_x_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - Visualizing the fair function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x110e2b750>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110bf1d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5,5,0.001)\n",
    "y = fair_obj(x,0.1)\n",
    "f, (ax1, ax2,ax3) = plt.subplots(3, 1, sharex=True)\n",
    "ax1.plot(x,y.func()); ax1.set_title('function')\n",
    "ax2.plot(x,y.jacob(),color = 'r'); ax2.set_title('Jacob')\n",
    "ax3.plot(x,y.hess(),color = 'g'); ax3.set_title('Hessian')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - Fair function\n",
    "\n",
    "Notice that there is a parameter within the fair function `c`. The smaller the value of c, the closer it approximates the `MAE` function. Suppose we increase `0.1` to `1` instead:\n",
    "\n",
    "** You can probably notice that the higher the 'c' parameter is, the smoother the computation and hence lesser training time at the cost of accuracy. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEKCAYAAAD0Luk/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11071c190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-1,1,0.001)\n",
    "y = fair_obj(x,1)\n",
    "f, (ax1, ax2,ax3) = plt.subplots(3, 1, sharex=True)\n",
    "ax1.plot(x,y.func()); ax1.set_title('function')\n",
    "ax2.plot(x,y.jacob(),color = 'r'); ax2.set_title('Jacob')\n",
    "ax3.plot(x,y.hess(),color = 'g'); ax3.set_title('Hessian');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - Fair function in xgb\n",
    "\n",
    "So how do i do this with XGB? Start by defining the fair objective:\n",
    "\n",
    "```python\n",
    "\n",
    "def fair_obj(preds, dtrain):\n",
    "    fair_constant = 2\n",
    "    labels = dtrain.get_label()\n",
    "    x = (preds - labels)\n",
    "    den = abs(x) + fair_constant\n",
    "    grad = fair_constant * x / (den)\n",
    "    hess = fair_constant * fair_constant / (den * den)\n",
    "    return grad, hess\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBOOST - Fair function in xgb\n",
    "\n",
    "And feed it inside `xgb.train`:\n",
    "\n",
    "```python\n",
    "xgb.train(params,\n",
    "            d_train,\n",
    "            100000,\n",
    "            watchlist,\n",
    "            early_stopping_rounds=early_stop,\n",
    "            obj=fair_obj,\n",
    "            eval_metric='mse')\n",
    "```            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results so far\n",
    "\n",
    "- With a few variants of my Xgboost and (weighted) averaging them, i (initially) got into top 10%.\n",
    "\n",
    "- Unfortunately within no time at all i was on the verge of getting kick out of 10%, and there were no further improvements possible (based on the fourms) from Xgb.\n",
    "\n",
    "- Many people in the fourms suggested Neural Networks ** which i have absolutely no experience or knowledge ** other than the ones i did on MOOCS!\n",
    "\n",
    "- The idea is to use two different models so that they can 'look out' for each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Networks! \n",
    "\n",
    "My first ever Deep neural network! (Outside Moocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Networks - Building one with Keras \n",
    "\n",
    "It turns out to be really easy to build Neural Networks with `Keras`:\n",
    "\n",
    "```python\n",
    "def nn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(400, input_dim = xtrain.shape[1], init = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "        \n",
    "    model.add(Dense(200, init = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(100, init = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(50, init = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1, init = 'he_normal'))\n",
    "    model.compile(loss = 'mae', optimizer = 'adadelta',metrics=[mae])\n",
    "    return(model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Networks -Training and tuning NN. \n",
    "\n",
    "- Each fold still required ~ 33 minutes approx which also made it very hard to iterate different features. \n",
    "\n",
    "- One simple improvement (or quick win) is to bag the neural networks. \n",
    "\n",
    "- However with my mac book pro, it would still take (40\\*55\\*10 = 22000 seconds) 6.1 hours just for training one model alone! \n",
    "\n",
    "- Bagging it 10 times would take close to 3 days which is roughly what the fourms reported. \n",
    "\n",
    "- Time is not on my side!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Networks - Training NN on AWS (CUDA) \n",
    "\n",
    "- This was about 10-12 remaining days into the competition.\n",
    "- No choice but to learn how to set up GPU instances on AWS. (Spend slightly over a day to figured it out) \n",
    "- Wrote my own small tutorial [here](https://github.com/Freedom89/aws_configure/blob/master/AWS_ec2_deep_learning_stack.md).\n",
    "\n",
    "\n",
    "## Huge Mistake (Oversight)\n",
    "\n",
    "After setting up Theano and CUDA with CUDNN, i forgot to set the [cnmem] parameter.\n",
    "\n",
    "What it does essentially it forces the system to allocate the gpu memory to the application you are using. Below is basically a summary of run-times:\n",
    "\n",
    "|Type|Mac|AWS C4.6x|Theano|Theano w cnmem|\n",
    "|---|---|---|---|---|---|\n",
    "|Time|40-44|24-28|18|12|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Networks - Some Tricks with NN\n",
    "\n",
    "- In XGB, you have\n",
    "  - `early_stopping_rounds = value`\n",
    "  - `clf.predict(d_valid, ntree_limit=clf.best_ntree_limit)`\n",
    "  \n",
    "- Could you do the same with Neural Networks?\n",
    " \n",
    " \n",
    "- Note that if you use early stopping you could be overfitting to the validation data and hence the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Networks - Early Stopping of Neural Networks \n",
    "\n",
    "Its easy!\n",
    "\n",
    "```python\n",
    "\n",
    "model = nn_model()\n",
    "\n",
    "callsback_list = [EarlyStopping(patience=10), \\\n",
    "                  ModelCheckpoint('keras-regressor-' + str(i+1) +'_'+ str(j+1) + '.check',\\\n",
    "                  monitor='val_loss', save_best_only=True, verbose=0)]\n",
    "\n",
    "fit = model.fit_generator(generator = batch_generator(xtr, ytr, 128, True),\n",
    "                          nb_epoch = nepochs,\n",
    "                          samples_per_epoch = xtr.shape[0],\n",
    "                          verbose = 0,\n",
    "                          validation_data=(xte.todense(),yte),\n",
    "                          callbacks=callsback_list)       \n",
    "\n",
    "fit = load_model('keras-regressor-' + str(i+1) + '_'+ str(j+1) + '.check')\n",
    "```\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results so far\n",
    "\n",
    "- With simple averaging / using leaderboard as a feedback, i got into top 5%. \n",
    "- With that, i changed my goal to top 5%! \n",
    "- I needed more safety net to ensure that i would be in the top 5% \n",
    "- Additionally, i got kicked out of top 5% in no time at all. \n",
    "\n",
    "## Side note\n",
    "\n",
    "- With the best submission of this approach, i would have gotten rank 276 which barely made it to top 10%.\n",
    "- There were a sudden surge of experts entering the competition (as an earlier one ended). \n",
    "- Possibly other factors as people started stacking their models. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking - Horrors! \n",
    "\n",
    "The moment i decided to do stacking (with 7days remaining), i realized i do not have my out-of-fold predictions.\n",
    "\n",
    "For those of you who are not familar with stacking, here is a high level idea:\n",
    "\n",
    "* Take your data set, split into n-folds.\n",
    "* Train your model with (n-1) folds and predict on the **remaining fold (out of bag)** and the test set. \n",
    "* Combine (stack) the predictions on the remaining folds \n",
    "* Average the predictions for the test set.\n",
    "* These will form the meta-features for your second level modeling, which is stacking.\n",
    "\n",
    "#### Thus, i had to re-train all my previous models, and one additional random forest and extra trees each with out of bag predictions!\n",
    "\n",
    "* I also trained a few other models, such as Neural Network without log-transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking - Mistakes! \n",
    "\n",
    "* As my folds were very different in terms of cv-score, i had to use early stopping. \n",
    "* Try to make cv-scores across folds more consistent. (It turns out that it did not help much, and i still had descent results) \n",
    "* Majority of the errors came from data points which has high target values, etc 9000 but model predicts 5000 which contributed significantly to the MAE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking - Simple Weighted Average\n",
    "\n",
    "Combine all your meta-features to one data frame. [Notebook here](https://github.com/Freedom89/Allstate_kaggle/blob/master/second_level_models/combine_data.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993.587402</td>\n",
       "      <td>1991.582031</td>\n",
       "      <td>2040.753906</td>\n",
       "      <td>2037.662842</td>\n",
       "      <td>2011.458252</td>\n",
       "      <td>2031.191162</td>\n",
       "      <td>1709.747961</td>\n",
       "      <td>1863.231165</td>\n",
       "      <td>1867.304663</td>\n",
       "      <td>1817.927966</td>\n",
       "      <td>2177.778654</td>\n",
       "      <td>2059.030370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1785.814331</td>\n",
       "      <td>1760.319946</td>\n",
       "      <td>1782.887695</td>\n",
       "      <td>1801.068604</td>\n",
       "      <td>1761.099731</td>\n",
       "      <td>1786.076660</td>\n",
       "      <td>1472.165295</td>\n",
       "      <td>1518.536694</td>\n",
       "      <td>1465.007471</td>\n",
       "      <td>1472.942126</td>\n",
       "      <td>1884.687448</td>\n",
       "      <td>1700.372436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4657.417480</td>\n",
       "      <td>4471.034180</td>\n",
       "      <td>4556.829590</td>\n",
       "      <td>4361.276367</td>\n",
       "      <td>4409.905762</td>\n",
       "      <td>4420.834961</td>\n",
       "      <td>4131.383081</td>\n",
       "      <td>3913.994287</td>\n",
       "      <td>3883.456030</td>\n",
       "      <td>3798.080249</td>\n",
       "      <td>4037.687796</td>\n",
       "      <td>3863.859438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1038.933716</td>\n",
       "      <td>1063.732910</td>\n",
       "      <td>1086.600220</td>\n",
       "      <td>1084.421143</td>\n",
       "      <td>1074.311401</td>\n",
       "      <td>1078.842163</td>\n",
       "      <td>1038.551477</td>\n",
       "      <td>987.047913</td>\n",
       "      <td>952.744666</td>\n",
       "      <td>1040.312915</td>\n",
       "      <td>1134.017057</td>\n",
       "      <td>1163.973155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3166.384033</td>\n",
       "      <td>3289.858887</td>\n",
       "      <td>3324.271240</td>\n",
       "      <td>3269.665527</td>\n",
       "      <td>3485.719971</td>\n",
       "      <td>3238.185791</td>\n",
       "      <td>3147.510742</td>\n",
       "      <td>3263.374414</td>\n",
       "      <td>3241.944531</td>\n",
       "      <td>3269.075391</td>\n",
       "      <td>3307.724160</td>\n",
       "      <td>2948.707217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1            2            3            4  \\\n",
       "0  1993.587402  1991.582031  2040.753906  2037.662842  2011.458252   \n",
       "1  1785.814331  1760.319946  1782.887695  1801.068604  1761.099731   \n",
       "2  4657.417480  4471.034180  4556.829590  4361.276367  4409.905762   \n",
       "3  1038.933716  1063.732910  1086.600220  1084.421143  1074.311401   \n",
       "4  3166.384033  3289.858887  3324.271240  3269.665527  3485.719971   \n",
       "\n",
       "             5            6            7            8            9  \\\n",
       "0  2031.191162  1709.747961  1863.231165  1867.304663  1817.927966   \n",
       "1  1786.076660  1472.165295  1518.536694  1465.007471  1472.942126   \n",
       "2  4420.834961  4131.383081  3913.994287  3883.456030  3798.080249   \n",
       "3  1078.842163  1038.551477   987.047913   952.744666  1040.312915   \n",
       "4  3238.185791  3147.510742  3263.374414  3241.944531  3269.075391   \n",
       "\n",
       "            10           11  \n",
       "0  2177.778654  2059.030370  \n",
       "1  1884.687448  1700.372436  \n",
       "2  4037.687796  3863.859438  \n",
       "3  1134.017057  1163.973155  \n",
       "4  3307.724160  2948.707217  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "train_x = pd.read_csv(\"../kaggle_1/train_second_level_model.csv\")\n",
    "train_x.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking - Simple Weighted Average (cont)\n",
    "\n",
    "Printing the loss for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1124.2522893\n",
      "1125.11043344\n",
      "1124.73870933\n",
      "1125.09915962\n",
      "1124.87963343\n",
      "1124.45611729\n",
      "1130.58667325\n",
      "1130.40016748\n",
      "1131.39946641\n",
      "1132.36796706\n",
      "1190.29358276\n",
      "1186.37357485\n"
     ]
    }
   ],
   "source": [
    "for i in range(train_x.shape[1]):\n",
    "    print mean_absolute_error(train_x.ix[:,i],data.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking - Simple Weighted Average (cont)\n",
    "\n",
    "Simple Averaging:\n",
    "\n",
    "(But previously i was using leaderboard feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119.97406917\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.5\n",
    "print mean_absolute_error(ratio*train_x.ix[:,0]+(1-ratio)*train_x.ix[:,7],data.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119.7183677\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.65\n",
    "print mean_absolute_error(ratio*train_x.ix[:,0]+(1-ratio)*train_x.ix[:,7],data.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120.3049399\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.75\n",
    "print mean_absolute_error(ratio*train_x.ix[:,0]+(1-ratio)*train_x.ix[:,7],data.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking - Simple Weighted Average (cont)\n",
    "\n",
    "Finally lets look at a way of finding optimal ratio for multiple inputs:\n",
    "\n",
    "Define the following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def mae_func(weights):\n",
    "    ''' scipy minimize will pass the weights as a numpy array '''\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, predictions):\n",
    "            final_prediction += weight*prediction\n",
    "\n",
    "    return mean_absolute_error(Y_values, final_prediction)\n",
    "\n",
    "Y_values = data['loss'].values\n",
    "predictions = []\n",
    "for i in range(11):\n",
    "    predictions.append(train_x.ix[:,i])\n",
    "lls = []\n",
    "wghts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print(' Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking - Simple Weighted Average (cont)\n",
    "\n",
    "Finding the optimal weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Ensemble Score: 1118.46592553\n",
      "\n",
      " Best Weights: [ 0.1317671   0.05049913  0.09826599  0.12918516  0.0616241   0.11857319\n",
      "  0.06449542  0.09522439  0.16919281  0.09825817  0.        ]\n",
      " Time taken: 0 hours 0 minutes and 13.92 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = timer(None)\n",
    "for i in range(5):\n",
    "    starting_values = np.random.uniform(size=len(predictions))\n",
    "    bounds = [(0,1)]*len(predictions)\n",
    "    res = minimize(mae_func, starting_values, method='L-BFGS-B',\n",
    "                   bounds=bounds, options={'disp': False, 'maxiter': 10})\n",
    "    lls.append(res['fun'])\n",
    "    wghts.append(res['x'])\n",
    "    # Uncomment the next line if you want to see the weights and scores calculated in real time\n",
    "    #print('Weights: {weights}  Score: {score}'.format(weights=res['x'], score=res['fun']))\n",
    "bestSC = np.min(lls)\n",
    "bestWght = wghts[np.argmin(lls)]\n",
    "print('\\n Ensemble Score: {best_score}'.format(best_score=bestSC))\n",
    "print('\\n Best Weights: {weights}'.format(weights=bestWght))\n",
    "timer(start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results so far\n",
    "- By now, i was hovering around 5% in the public leaderboard with 2 days left.\n",
    "- There was no guarantee i would remain in the top 5% in the private leader board.\n",
    "- To be precise, this score placed me at position 135 at the public leaderboard - borderline top 5%\n",
    "- Required more safety Net! \n",
    "\n",
    "It turns out that with the simple weighted average model i would have been placed 104, close to the top 3%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking - Unfortunately...\n",
    "\n",
    "- I tried linear regression, but the results is worse than the weighted average approach.\n",
    "- It made sense, as linear regression uses MSE rather than MAE. \n",
    "\n",
    "## XGB to the rescue perhaps?\n",
    "\n",
    "- **NOPE!**\n",
    "- XGB overfitted to my single best xgb model instead. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking - With (slightly more than) one day to go, \n",
    "\n",
    "I decided to try Neural Networks instead.\n",
    "\n",
    "The best local cv with the weighted average was `1118.345`\n",
    "\n",
    "Here is the output with my first neural network:\n",
    "\n",
    "```\n",
    "('Fold ', 1, '- MAE:', 1117.5260825665521)\n",
    "('Fold ', 2, '- MAE:', 1113.2272453103922)\n",
    "('Fold ', 3, '- MAE:', 1117.1135764027533)\n",
    "('Fold ', 4, '- MAE:', 1121.9982577768997)\n",
    "('Fold ', 5, '- MAE:', 1119.6595219061744)\n",
    "('Total - MAE:', 1117.9049057391971)\n",
    "```\n",
    "**Finally! Some improvement! **\n",
    "\n",
    "And the private LB would have given me position 53! \n",
    "\n",
    "Clearly i am onto something, right? **No.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking - Whats are the first few things to try?\n",
    "\n",
    "1. Tuning \n",
    " - Luckily with only 11 features, it is relatively fast (~40minutes) for each model to try new params.\n",
    " - Unfortunately, no matter what i did, i got results worse than my weighted average cv score. \n",
    " - With no choice, i resorted to bagging\n",
    "2. Bagging\n",
    " - Manage to achieve a lower CV score, lower public score, but a worst private score. \n",
    " \n",
    "So i guess, sometimes **luck** does play a part. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking - Finally.. \n",
    "\n",
    "i combine my keras (out of bag) results (consider them third level modeling) and combine with my second level models and ran the weighted average codes. \n",
    "\n",
    "Below is a summary of what i achieved: \n",
    "\n",
    "|            | Single Keras | W. avg with single NN | Bagged 5 Keras | W.avg  both NN |\n",
    "| :--------- | :------------------ | :------------------------- | :------------------ | :----------------------------------- |\n",
    "| Local CV   | 1117.90490574       | 1117.77760897              | 1117.88037992       | 1117.7181697                        |\n",
    "| Public LB  | 1100.90013          | 1100.87763                 | 1100.88155          | 1100.86946                           |\n",
    "| Private LB | 1112.84611          | 1112.77244                 | 1112.93370          | 1112.73936                           |\n",
    "\n",
    "What is interesting is that the weighted average with my single Neural Netwrok outperformed the one that is bagged 5 times. \n",
    "\n",
    "I decided to run weighted average with both single and bagged Neural Network. Turns out i had best Cv results across all measures.\n",
    "\n",
    "Final position - 46! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# END\n",
    "\n",
    "# Hope you have enjoyed it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
